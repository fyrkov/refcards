### S3

S3 buckets are defined at region level.\
Objects in buckets are defined by keys. Key is a **full path**, e.g. `s3://my-bucket/my_folder/subfolder/file.txt`.\
Max object size is **5TB**.\
To upload a file > **5GB** must use a **"multi-part upload"**.\
Objects can have attached `tags` - useful for security / lifecycle.\
Objects can have `metadata` - list of text key-value pairs.\
Objects can have a `version id` if versioning is enabled.

A bucket name must be **globally unique** across all accounts in AWS.\
Buckets are created in regions, i.e. they are not global themselves.

Objects have public URLs and pre-signed URLs directly from AWS console with embedded temporary credentials.

#### Versioning
Versioning is enabled at the bucket level.\
Re-uploading existing file at some url. Same key get incremented version.\
Use cases: protect from unintended deletes, easy roll back.\
Suspending versioning does not delete created versions.\
Object added before versioning is enabled has `null` Version ID.\
Normally Version ID is a random string.

Delete an object operation is a "soft delete" - a "delete marker" is applied to an object and is treated like a version.\
To restore a file it is required to delete a "delete marker".\
Deleting a "delete marker" or a specific version (not an object itself) is a permanent delete and removes these versions from the object.

#### Encryption
4 ways to encrypt objects in S3:
* SSE-S3 using keys managed by AWS. SSE = server side encryption. Algo is AES-256. Must set HTTP header `x-aws-server-side-encryption":"AES256"`. In this case the key is entirely managed by AWS.
* SSE-KMS using AWS KMS. KMS gives user control over keys and audit. Must set HTTP header `x-aws-server-side-encryption":"aws:kms"`. A KMS key is bound to a bucket upon bucket creation.
* SSE-C client manages keys. HTTPS must be used and an encryption key must be provided in HTTP headers for every request. Can be done only via CLI.
* Client side encryption. A client encrypts objects before sending to S3. A Client can use "Amazon S3 Encryption Client".

Different versions of the same objects can be non-encrypted and encrypted.

Glacier encrypts data by default.

#### Security

:exclamation: S3 buckets do not have SGs.

1. User based sec. IAM policies define which API calls are allowed for specific users.
2. Resource based.
    * Bucket policies. JSON based policies. Allows cross-account access.
    * Object Access Control List (ACL) - finer grain
    * Bucket Access Control List (ACL) - less common.

IAM principal can access an S3 object if IAM permissions allow it **OR** resource policy allows it **AND** there is no explicit deny.

Common use cases for bucket policies:
* grant public access to bucket
* force object encryption upon upload
* grant cross-account access

There is a way to block public access to a bucket in settings - "Block Public Access".\
This setting was created historically to prevent data leaks.\
"Block Public Access" can be defined at bucket and account levels.

Logging and audit:
* S3 access logs can be stored in another S3 bucket
* API calls can be logged in AWS CloudTrail

Additional user security:
* MFA for delete object operations.
* Pre-signed URLs valid for limited period of time. Use case: premium video service for logged in users.

To ease policy creation a https://awspolicygen.s3.amazonaws.com/ can be used.

#### S3 Websites
S3 can host static websites.
A URL will be like one of the following
* `<bucket>.s3-website-<aws_region>.amazonaws.com`
* `<bucket>.s3-website.<aws_region>.amazonaws.com`

A bucket can enable static website hosting in bucket properties.\
It requires to specify an index file document and an error document.\
A bucket must be set to have a public access.

#### CORS
An origin is a protocol + host + port.\
Browsers block requests to other origins unless they are explicitly allowed by that another origin.\
Browser visiting an origin host `https://example.com` does a pre-flight request to the cross-origin:
```
OPTIONS /
Host: www.cross-origin.com
Origin:  https://example.com
```
and gets a pre-flight response
```
Access-Control-Allow-Origin: https://example.com
Access-Control-Allow-Methods: GET, PUT...
```

In case of S3 Website hosting an additional bucket with assets must be configured to have right CORS permissions.\
This is done in buckets permissions as a JSON doc.

#### Consistency
All operations in S3 are strongly consistent after December 2020.\
It means that after each delete all subsequent reads or lists will not see the object.

#### MFA delete
Can be used when versioning is enabled.\
MFA delete affects only permanent deletes, not "delete markers".\
Only root account can toggle MFA delete.\
MFA delete can only be enabled using CLI (not yet in Console).

#### Access logs
All requests logs can be stored in another S3 bucket.\
:exclamation: do not set a logging bucket to be the monitored bucket - it creates a logging loop.

Enabled in Bucket > Properties > Server access logging

The logs can be analyzed at scale using AWS Athena.

#### S3 Replication
Versioning must be enabled in source and replica.\
This is async replication.\
Enabling replication is not retroactive.\
There is not *chaining replication*, i.e. if bucket3 <- bucket2 and bucket2 <- bucket1, then objects added in the bucket1 will not be replicated in the bucket3.

1. CRR - cross region replication. Use cases: compliance, lo latency, cross accounts replication.
2. SRR - same region replication. Use cases: log aggregation from apps.

For delete operations:
* can replicate delete markers (optional setting)
* deletions with version id are not replicated (to avoid malicious deletes)

Replication is setup in the Management > Replication rules

#### Pre-signed URLs
Cane be generated
* for downloads via CLI or SDK
* for uploads visa SDK

Pre-signed URLs are valid for 3600s by default. This can be changed with the `--expires-in` parameter.\
Users given a pre-signed URL inherit permissions of the person who generated the URL for GET/PUT.

Use cases:
* Allow only logged in users to download a video from S3
* Allow an ever changing list of users to download files by generating URLs dynamically
* Allow temporary a user to upload a file to a precise location in a bucket

How to generate a pre-signed URL via CLI?
```
aws s3 presign s3:://bucket/object --region eu-west-1 --expires-in 300
```

#### S3 Storage classes

:exclamation: Storage class is specified not per bucket but when an object is uploaded

* S3 Standard - general purpose. Use case: frequently accessed data (more than once in a month).
* S3 Standard-Infrequent Access (IA). Lower cost. Use cases: backups. There is a retrieval fee. Minimum storage duration is 30 days.
  * S3 One Zone-Infrequent Access. Same as IA but data in a single AZ. Lower cost than IA.
* S3 Intelligent Tiering. Automatically moves objects between 2 tiers: general purpose and IA. Small monthly auto-tiering fee. Use case: data with changing or unknown access patterns.
* S3 Glacier Flexible Retrieval. Lo cost + retrieval cost. Data is retained for longer terms. Minimum storage duration is 90 days. Use cases: long-lived archive data accessed ~once a year. Retrieval options:
  * Expedited, 1-5 mins
  * Standard, 3-5 hr
  * Bulk, 5-12 hr
* S3 Glacier Instant Retrieval
* S3 Glacier Deep Archive. Lowest costs + retrieval cost. Minimum storage duration is 180 days. Retrieval options:
  * Standard, 12 hr
  * Bulk, 48 hr

To get a file in Glacier it is necessary first to "initiate restore" for it.

#### S3 Object lock
Versioning must be enabled.\
Blocks an object from deletion for a specified amount of time.\
Object retention:
* **Retention Period** specifies a fixed period
* **Legal Hold** - no expiry date

You can place a retention period on an object version either explicitly or through a bucket default setting.\
When you apply a retention period to an object version explicitly, you specify a `Retain Until Date` for the object version.
When you use bucket default settings, you don't specify a `Retain Until Date`.\
Instead, you specify a duration, in either days or years, for which every object version placed in the bucket should be protected.

#### S3 Lifecycle rules
There is an option to move objects between storage classes.

Lifecycle rules define how to automatically
* move current versions of objects between storage classes
* move previous versions of objects between storage classes
* expire current versions of objects (i.e. delete objects)
* delete previous versions of objects
* delete expired delete markers or incomplete multipart uploads.

Lifecycle rules are specified in Management > Lifecycle rules

#### S3 Performance
1. S3 has hi performance but when encryption is enabled it can be affected by KMS API quotas.\
KMS API is called to generate a key when a file is uploaded or to decrypt when a file is downloaded.\
There is a KMS quota - 5500, 10000, 30000 req/s based on region.\
Quota can be increased by request in Service Quotas Console.

2. Must use multipart upload for files >5GB and should use multipart upload for files >100MB

3. S3 **Transfer Acceleration** increases transfer speed by transferring a file to an AWS "edge location"
and then forwarding it to a target bucket in a target region.

4. S3 **Byte-range fetches** parallelize GETs in chunks to speed up downloads

#### S3 Select and Glacier Select
S3 Select can filter by rows and columns with SQL statements.\
Use case: retrieve less data using SQL and performing server-side filtering.\
As a result less network transfer, saving up costs.

#### S3 Event Notifications
Object can be created, removed, restored...\
Event notification rules can be created to react in some way to these events.\
Rules can filter objects by names.

Use case: generate thumbnails upon images uploading event.

S3 Events can be captured by:
* SQS. Required Access Policy to allow S3 to send messages
* SNS. The same?
* Lambda. The same?

Event notification can be found under Properties > Event Notifications

#### Requester pays
Usually a bucket owner pays for both storage and network transfer.\
It is possible to "Requester pays" buckets so that network transfer costs are paid by requester.\
In this case a requester must be in another AWS account.

#### Athena
Serverless query service to perform analytics against S3 objects.\
Uses SQL language to query files.\
Supports CSV, JSON, Avro and other data formats.

Use case: create a table from Access Logs in Athena  and query them with SQL.
